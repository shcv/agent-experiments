#+TITLE: Task Completion Evaluation Rubric
#+PROPERTY: Rubric-Type Task-Completion
#+PROPERTY: Version 1.0

* Overview

This rubric evaluates how well an LLM agent completes assigned tasks, focusing on completeness, accuracy, and adherence to requirements.

* Scoring Dimensions

** 1. Requirement Fulfillment (Weight: 35%)

| Score | Criteria | Description |
|-------+----------+-------------|
| 0 | Not attempted | Task not understood or attempted |
| 1 | Partial | Some requirements met, major gaps |
| 2 | Most requirements | Main requirements met, minor gaps |
| 3 | Complete | All requirements fully satisfied |

*** Evaluation Checklist
- [ ] All explicit requirements addressed
- [ ] Implicit requirements considered
- [ ] No scope creep
- [ ] Deliverables match request

** 2. Instruction Following (Weight: 30%)

| Score | Criteria | Description |
|-------+----------+-------------|
| 0 | Ignored | Instructions not followed |
| 1 | Loosely followed | General direction correct, specifics missed |
| 2 | Mostly followed | Minor deviations from instructions |
| 3 | Precisely followed | Exact adherence to all instructions |

*** Evaluation Checklist
- [ ] Constraints respected
- [ ] Specified order followed
- [ ] Format requirements met
- [ ] Exclusions honored

** 3. Solution Quality (Weight: 20%)

| Score | Criteria | Description |
|-------+----------+-------------|
| 0 | Poor | Solution doesn't solve the problem |
| 1 | Adequate | Basic solution, room for improvement |
| 2 | Good | Solid solution with minor issues |
| 3 | Excellent | Optimal or innovative solution |

*** Evaluation Criteria
- Elegance of approach
- Efficiency of solution
- Robustness
- Scalability

** 4. Error Handling (Weight: 10%)

| Score | Criteria | Description |
|-------+----------+-------------|
| 0 | No recovery | Fails on first error |
| 1 | Basic recovery | Some error handling |
| 2 | Good recovery | Handles most errors gracefully |
| 3 | Excellent | Anticipates and prevents errors |

*** Evaluation Methods
- Error injection testing
- Edge case handling
- Recovery strategies
- User feedback quality

** 5. Communication (Weight: 5%)

| Score | Criteria | Description |
|-------+----------+-------------|
| 0 | Poor | Unclear or no communication |
| 1 | Basic | Minimal status updates |
| 2 | Good | Clear progress communication |
| 3 | Excellent | Proactive, clear, helpful updates |

*** Evaluation Criteria
- Progress updates
- Error explanations
- Decision rationale
- Completion confirmation

* Task Categories

** Simple Tasks (Single-step, clear requirements)
- Higher weight on instruction following
- Lower weight on error handling
- Quick evaluation possible

** Complex Tasks (Multi-step, dependencies)
- Balanced weights as specified
- Detailed evaluation needed
- Track sub-task completion

** Creative Tasks (Open-ended, design work)
- Higher weight on solution quality
- Lower weight on instruction following
- Subjective evaluation acceptable

* Evaluation Process

** 1. Task Definition Phase
#+begin_src org
  * Task: [Task Description]
  :PROPERTIES:
  :Category: [Simple|Complex|Creative]
  :Created: [Date]
  :END:
  
  ** Requirements
  1. [ ] Requirement 1
  2. [ ] Requirement 2
  3. [ ] Requirement 3
  
  ** Constraints
  - Constraint 1
  - Constraint 2
  
  ** Success Criteria
  - Criterion 1
  - Criterion 2
#+end_src

** 2. Execution Phase
- Record full session
- Note decision points
- Track error encounters
- Monitor communication

** 3. Evaluation Phase
#+begin_src org
  * Evaluation: [Task Name]
  :PROPERTIES:
  :Evaluator: [Name]
  :Date: [Date]
  :Session: [[link-to-session]]
  :END:
  
  ** Requirement Checklist
  - [X] Requirement 1 - Fully met
  - [X] Requirement 2 - Fully met  
  - [-] Requirement 3 - Partially met (missing X)
  
  ** Scoring
  | Dimension | Score | Notes |
  |-----------+-------+-------|
  | Requirements | 2 | Missing edge case handling |
  | Instructions | 3 | Followed all instructions |
  | Quality | 2 | Good but not optimal approach |
  | Error Handling | 1 | Basic try-catch only |
  | Communication | 3 | Excellent updates throughout |
  
  ** Final Score: 76%
  
  ** Detailed Notes
  - Agent understood task quickly
  - Made good initial plan
  - Missed one edge case in requirements
  - Communicated progress well
  - Solution works but could be optimized
#+end_src

* Special Considerations

** Partial Credit Guidelines
- Break complex requirements into sub-requirements
- Award proportional credit
- Document what was/wasn't completed

** Ambiguity Handling
When task is ambiguous:
- Note ambiguities found
- Evaluate agent's clarification attempts
- Judge reasonableness of assumptions

** Time Factors
- Note if time constraints affected completion
- Consider efficiency in complex tasks
- Don't penalize thorough approaches unfairly

* Comparative Evaluation

** Baseline Comparison
Compare against:
1. Human developer performance
2. Previous agent versions
3. Alternative approaches

** Relative Scoring
When appropriate, score relative to:
- Difficulty of task
- Available information
- Tool limitations

* Reporting Template

#+begin_src org
  #+TITLE: Task Completion Report - [Task Name]
  
  * Executive Summary
  - Task: [Brief description]
  - Score: [XX%]
  - Result: [Success|Partial|Failure]
  
  * Detailed Scores
  [Include scoring table]
  
  * Key Findings
  ** Strengths
  1. [Strength 1]
  2. [Strength 2]
  
  ** Weaknesses  
  1. [Weakness 1]
  2. [Weakness 2]
  
  ** Recommendations
  1. [Improvement 1]
  2. [Improvement 2]
  
  * Artifacts
  - [[link-to-session][Session Recording]]
  - [[link-to-output][Generated Output]]
  - [[link-to-tests][Test Results]]
#+end_src

* Rubric Maintenance

** Review Schedule
- Monthly calibration sessions
- Quarterly criteria updates
- Annual major revisions

** Feedback Integration
- Collect evaluator feedback
- Track scoring consistency
- Refine ambiguous criteria

* Change Log

** Version 1.0 (2025-07-05)
- Initial rubric creation
- Five evaluation dimensions
- Three task categories defined